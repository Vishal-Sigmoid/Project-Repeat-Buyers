{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Merged User info, activity log and training and testing data on user-merchant pairs\n",
    "# df = pd.read_csv(\"/Users/Vishal/Project_1/final.csv\")\n",
    "\n",
    "# #Replace null values in columns with corresponding values\n",
    "\n",
    "# df['age_range'] = df['age_range'].fillna(0)\n",
    "# df['label'] = df['label'].fillna(2)\n",
    "# df['gender'] = df['gender'].fillna(2)\n",
    "# df['brand_id'] = df['brand_id'].fillna(0)\n",
    "\n",
    "# # Convert time stamp to Year-Month-Date format\n",
    "# df['time_stamp'] = pd.to_datetime(df['time_stamp'], format='%m%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data from format 1\n",
    "df_train = pd.read_csv(\"/Users/Vishal/Project_1/data_format1/train_format1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv(\"/Users/Vishal/Project_1/df_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort\n",
    "df_combined = df_combined.sort_values(['user_id','seller_id'])\n",
    "df_train = df_train.sort_values(['user_id','seller_id'])\n",
    "\n",
    "final_feat = (df_combined.drop(['user_id', 'seller_id', 'label','age_gender', 'user_merchant_pair'], axis=1))\n",
    "\n",
    "final_label = df_train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-FOLD STRATIFIED SPLIT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgboost(x, y):\n",
    "    \n",
    "    model = xgb.XGBClassifier(max_depth = 6)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 2)\n",
    "    \n",
    "    AUC_valid = []\n",
    "    AUC_train = []\n",
    "    \n",
    "    for train_index, valid_index in skf.split(x, y):\n",
    "    \n",
    "        #print(\"TRAIN:\", train_index, \"VALID:\", valid_index)\n",
    "    \n",
    "        X_train, X_valid = x.iloc[train_index], x.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    \n",
    "        model.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "        auc_valid = roc_auc_score(y_valid, model.predict_proba(X_valid)[:,1])\n",
    "        #print(auc_valid)\n",
    "        AUC_valid.append(auc_valid)\n",
    "    \n",
    "        auc_train = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n",
    "        #print(auc_train)\n",
    "        AUC_train.append(auc_train)\n",
    "        \n",
    "        print('Iteration Complete!!')\n",
    "        \n",
    "    def mean(z):\n",
    "        return sum(z)/len(z)\n",
    "    \n",
    "    print(\"Mean auc for validation = \", mean(AUC_valid), \"\\t Mean auc for valid baseline = 0.6498\")\n",
    "    print(\"Mean auc for train = \", mean(AUC_train), \"\\t Mean auc for train baseline = 0.6629\")\n",
    "        \n",
    "    feat_imp_abs = model.feature_importances_\n",
    "    feat_imp_abs = pd.Series(data=feat_imp_abs,dtype='float')\n",
    "    feat_imp_norm = feat_imp_abs.div(feat_imp_abs.max())*100    \n",
    "        \n",
    "    feature_importance = list(final_feat)\n",
    "    feature_importance = pd.DataFrame(feature_importance)\n",
    "    feature_importance['importance_abs'] = feat_imp_abs\n",
    "    feature_importance['importance_norm'] = feat_imp_norm\n",
    "    feature_importance = feature_importance.rename(columns={0: \"feature\"})\n",
    "    \n",
    "    print(feature_importance.sort_values('importance_norm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = xgb.XGBClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Max depth 3\n",
    "# xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Max depth 4\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=4)\n",
    "\n",
    "# xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Max depth 5\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=5)\n",
    "\n",
    "# xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Max depth 6\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=6)\n",
    "\n",
    "# xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Mean auc for validation =  0.6784846625584459 \t Mean auc for valid baseline = 0.6498\n",
      "Mean auc for train =  0.7938491879476313 \t Mean auc for train baseline = 0.6629\n",
      "                                            feature  importance_abs  importance_norm\n",
      "137                               userselleronsale1        0.000000         0.000000\n",
      "138                               userselleronsale2        0.000000         0.000000\n",
      "134                           usersellerbeforesale1        0.000000         0.000000\n",
      "79                         unique_users_gender_norm        0.000000         0.000000\n",
      "151                         seller_count_of_label-1        0.000000         0.000000\n",
      "78                              gender_avg_purchase        0.000000         0.000000\n",
      "164         ratio_item_int_union_user_before_seller        0.000000         0.000000\n",
      "152          brand_intersection_user_before_on_sale        0.000000         0.000000\n",
      "162        item_intersection_user_before_and_seller        0.000000         0.000000\n",
      "161           item_intersection_user_before_on_sale        0.001651         3.295777\n",
      "23                                    userpurchase5        0.002077         4.145223\n",
      "84                    age_gender_purchase_days_norm        0.002129         4.249572\n",
      "3                                   userbeforesale1        0.002173         4.337137\n",
      "9                                       useronsale3        0.002257         4.504346\n",
      "8                                       useronsale2        0.002314         4.617450\n",
      "143              um_unique_brands_purchased_on_sale        0.002465         4.920574\n",
      "157         cat_intersection_user_before_and_seller        0.002626         5.241849\n",
      "82                     unique_users_age_gender_norm        0.002671         5.331552\n",
      "7                                       useronsale1        0.002688         5.364699\n",
      "75                                 age_avg_purchase        0.002735         5.458225\n",
      "76                            unique_users_age_norm        0.002766         5.519578\n",
      "43                                useravgpurchase11        0.002902         5.791924\n",
      "153       brand_intersection_user_before_and_seller        0.002956         5.899200\n",
      "54                        user_unique_items_on_sale        0.002958         5.904530\n",
      "51        user_unique_sellers_purchased_before_sale        0.002979         5.944941\n",
      "2                                   userbeforesale0        0.002992         5.972283\n",
      "168                           useractivity8diffmean        0.003051         6.088351\n",
      "33                                 useravgactivity8        0.003072         6.130520\n",
      "24                                    userpurchase6        0.003072         6.131275\n",
      "213                        sellerpurchase11diffmean        0.003136         6.258003\n",
      "0                                         age_range        0.003144         6.275566\n",
      "40                                 useravgpurchase8        0.003175         6.337716\n",
      "181                           userpurchase7diffmean        0.003183         6.352178\n",
      "190                                 userpurchase9/8        0.003189         6.364813\n",
      "189                                 userpurchase8/7        0.003210         6.406456\n",
      "202                               selleractivity7/6        0.003222         6.430037\n",
      "184                          userpurchase10diffmean        0.003223         6.431756\n",
      "192                               userpurchase11/10        0.003227         6.440041\n",
      "174                                 useractivity7/6        0.003317         6.619967\n",
      "59            user_unique_sellers_purchased_on_sale        0.003344         6.674753\n",
      "20                                    useractivity9        0.003364         6.714632\n",
      "188                                 userpurchase7/6        0.003382         6.750560\n",
      "67                                    selleronsale1        0.003387         6.760305\n",
      "165                           useractivity5diffmean        0.003404         6.793573\n",
      "136                               userselleronsale0        0.003405         6.794993\n",
      "140                        um_unique_brands_on_sale        0.003407         6.799270\n",
      "182                           userpurchase8diffmean        0.003441         6.868125\n",
      "61                            user_purchase_only_11        0.003449         6.884449\n",
      "149                         purchase_diff_from_1111        0.003473         6.932185\n",
      "18                                    useractivity7        0.003482         6.949085\n",
      "30                                 useravgactivity5        0.003484         6.953002\n",
      "45               user_unique_categories_before_sale        0.003490         6.964580\n",
      "71                                      userseller1        0.003495         6.974690\n",
      "38                                 useravgpurchase6        0.003503         6.990445\n",
      "177                                useractivity10/9        0.003505         6.995356\n",
      "172                             user_monthwise_mean        0.003509         7.003484\n",
      "187                                 userpurchase6/5        0.003538         7.060718\n",
      "42                                useravgpurchase10        0.003539         7.063359\n",
      "183                           userpurchase9diffmean        0.003549         7.083185\n",
      "49     user_unique_categories_purchased_before_sale        0.003561         7.106208\n",
      "37                                 useravgpurchase5        0.003566         7.117233\n",
      "160                 ratio_cat_int_union_user_seller        0.003577         7.139375\n",
      "31                                 useravgactivity6        0.003577         7.139527\n",
      "57         user_unique_categories_purchased_on_sale        0.003594         7.172212\n",
      "25                                    userpurchase7        0.003605         7.195852\n",
      "17                                    useractivity6        0.003622         7.229077\n",
      "178                               useractivity11/10        0.003625         7.235005\n",
      "32                                 useravgactivity7        0.003625         7.235884\n",
      "53                   user_unique_categories_on_sale        0.003626         7.237237\n",
      "29                                   userpurchase11        0.003637         7.258825\n",
      "166                           useractivity6diffmean        0.003649         7.282019\n",
      "39                                 useravgpurchase7        0.003660         7.304654\n",
      "41                                 useravgpurchase9        0.003735         7.454013\n",
      "28                                   userpurchase10        0.003738         7.461050\n",
      "34                                 useravgactivity9        0.003757         7.497648\n",
      "169                           useractivity9diffmean        0.003764         7.511401\n",
      "180                           userpurchase6diffmean        0.003771         7.526286\n",
      "175                                 useractivity8/7        0.003772         7.527766\n",
      "27                                    userpurchase9        0.003772         7.528139\n",
      "35                                useravgactivity10        0.003776         7.535478\n",
      "173                                 useractivity6/5        0.003776         7.536731\n",
      "58              user_unique_items_purchased_on_sale        0.003789         7.561385\n",
      "13                        user_ratio_3_to_2_on_sale        0.003800         7.584997\n",
      "133                           usersellerbeforesale0        0.003805         7.593568\n",
      "5                                   userbeforesale3        0.003814         7.612085\n",
      "125                    seller_unique_brands_on_sale        0.003817         7.618564\n",
      "155        ratio_brand_int_union_user_before_seller        0.003845         7.674410\n",
      "179                           userpurchase5diffmean        0.003853         7.690808\n",
      "147                         activity_diff_from_1111        0.003860         7.703154\n",
      "208                         sellerpurchase6diffmean        0.003870         7.723638\n",
      "6                                       useronsale0        0.003880         7.742997\n",
      "56             user_unique_brands_purchased_on_sale        0.003905         7.794343\n",
      "167                           useractivity7diffmean        0.003906         7.795859\n",
      "16                                    useractivity5        0.003907         7.798360\n",
      "170                          useractivity10diffmean        0.003914         7.811370\n",
      "204                               selleractivity9/8        0.003920         7.823677\n",
      "191                                userpurchase10/9        0.003928         7.838868\n",
      "197                         selleractivity9diffmean        0.003933         7.849690\n",
      "176                                 useractivity9/8        0.003946         7.875248\n",
      "121      seller_unique_brands_purchased_before_sale        0.003977         7.937539\n",
      "185                          userpurchase11diffmean        0.003989         7.960437\n",
      "158         ratio_cat_int_union_user_before_on_sale        0.004000         7.983832\n",
      "19                                    useractivity8        0.004007         7.996403\n",
      "218                               sellerpurchase9/8        0.004031         8.045617\n",
      "46                    user_unique_items_before_sale        0.004046         8.076128\n",
      "132           seller_unique_users_purchased_on_sale        0.004052         8.086197\n",
      "148                  activity_diff_from_second_last        0.004061         8.104506\n",
      "44                   user_unique_brands_before_sale        0.004065         8.112294\n",
      "12                        user_ratio_0_to_2_on_sale        0.004079         8.141621\n",
      "26                                    userpurchase8        0.004088         8.158557\n",
      "47                  user_unique_sellers_before_sale        0.004114         8.211664\n",
      "112                              selleravgpurchase7        0.004119         8.220946\n",
      "60                          user_all_month_purchase        0.004129         8.239973\n",
      "36                                useravgactivity11        0.004131         8.245541\n",
      "128                     seller_unique_users_on_sale        0.004146         8.275244\n",
      "74                                 age_avg_activity        0.004156         8.294013\n",
      "93                                  selleractivity9        0.004159         8.299962\n",
      "73                                      userseller3        0.004198         8.378616\n",
      "81                          age_gender_avg_purchase        0.004203         8.388133\n",
      "83                      age_gender_active_days_norm        0.004216         8.413886\n",
      "10                    user_ratio_0_to_2_before_sale        0.004220         8.421470\n",
      "1                                            gender        0.004233         8.448905\n",
      "156            cat_intersection_user_before_on_sale        0.004242         8.466907\n",
      "217                               sellerpurchase8/7        0.004247         8.475698\n",
      "63                                sellerbeforesale1        0.004259         8.501171\n",
      "11                    user_ratio_3_to_2_before_sale        0.004260         8.503205\n",
      "171                          useractivity11diffmean        0.004263         8.508065\n",
      "87                      seller_ratio_0_to_2_on_sale        0.004322         8.626533\n",
      "216                               sellerpurchase7/6        0.004322         8.626814\n",
      "219                              sellerpurchase10/9        0.004333         8.648872\n",
      "139                               userselleronsale3        0.004335         8.652623\n",
      "102                                sellerpurchase11        0.004336         8.653612\n",
      "214                  seller_purchase_monthwise_mean        0.004342         8.666245\n",
      "200                  seller_activity_monthwise_mean        0.004354         8.690505\n",
      "68                                    selleronsale2        0.004357         8.695241\n",
      "97                                  sellerpurchase6        0.004393         8.767380\n",
      "154       ratio_brand_int_union_user_before_on_sale        0.004400         8.782007\n",
      "98                                  sellerpurchase7        0.004405         8.791754\n",
      "211                         sellerpurchase9diffmean        0.004408         8.796931\n",
      "163        ratio_item_int_union_user_before_on_sale        0.004432         8.844791\n",
      "99                                  sellerpurchase8        0.004432         8.845349\n",
      "48         user_unique_brands_purchased_before_sale        0.004478         8.938009\n",
      "116                             selleravgpurchase11        0.004518         9.018110\n",
      "21                                   useractivity10        0.004563         9.107325\n",
      "89                                  selleractivity5        0.004572         9.124563\n",
      "111                              selleravgpurchase6        0.004604         9.189717\n",
      "205                              selleractivity10/9        0.004624         9.228257\n",
      "206                             selleractivity11/10        0.004654         9.288619\n",
      "203                               selleractivity8/7        0.004659         9.297656\n",
      "122  seller_unique_categories_purchased_before_sale        0.004678         9.337494\n",
      "104                              selleravgactivity6        0.004706         9.392945\n",
      "196                         selleractivity8diffmean        0.004713         9.406537\n",
      "198                        selleractivity10diffmean        0.004718         9.415836\n",
      "215                               sellerpurchase6/5        0.004730         9.440238\n",
      "91                                  selleractivity7        0.004731         9.442506\n",
      "100                                 sellerpurchase9        0.004734         9.449078\n",
      "14                                      active_days        0.004743         9.466405\n",
      "131           seller_unique_items_purchased_on_sale        0.004782         9.543772\n",
      "186                    user_purchase_monthwise_mean        0.004809         9.598217\n",
      "199                        selleractivity11diffmean        0.004813         9.606578\n",
      "150                  purchase_diff_from_second_last        0.004820         9.619916\n",
      "101                                sellerpurchase10        0.004875         9.730348\n",
      "119                 seller_unique_items_before_sale        0.004904         9.787373\n",
      "135                           usersellerbeforesale3        0.004912         9.803393\n",
      "130      seller_unique_categories_purchased_on_sale        0.004927         9.833639\n",
      "88                      seller_ratio_3_to_2_on_sale        0.004931         9.841629\n",
      "106                              selleravgactivity8        0.004967         9.913056\n",
      "117                seller_unique_brands_before_sale        0.004968         9.915544\n",
      "209                         sellerpurchase7diffmean        0.004983         9.945456\n",
      "95                                 selleractivity11        0.005003         9.985858\n",
      "120                 seller_unique_users_before_sale        0.005010         9.999780\n",
      "90                                  selleractivity6        0.005014        10.007407\n",
      "107                              selleravgactivity9        0.005024        10.026654\n",
      "105                              selleravgactivity7        0.005026        10.031508\n",
      "52                       user_unique_brands_on_sale        0.005029        10.036106\n",
      "193                         selleractivity5diffmean        0.005034        10.047349\n",
      "69                                    selleronsale3        0.005082        10.143501\n",
      "86                  seller_ratio_3_to_2_before_sale        0.005126        10.230524\n",
      "114                              selleravgpurchase9        0.005131        10.240292\n",
      "50          user_unique_items_purchased_before_sale        0.005134        10.246892\n",
      "80                          age_gender_avg_activity        0.005141        10.260090\n",
      "194                         selleractivity6diffmean        0.005143        10.265328\n",
      "22                                   useractivity11        0.005227        10.431900\n",
      "220                             sellerpurchase11/10        0.005235        10.447879\n",
      "96                                  sellerpurchase5        0.005263        10.504596\n",
      "110                              selleravgpurchase5        0.005279        10.535307\n",
      "94                                 selleractivity10        0.005326        10.630010\n",
      "103                              selleravgactivity5        0.005367        10.711882\n",
      "92                                  selleractivity8        0.005383        10.743511\n",
      "195                         selleractivity7diffmean        0.005456        10.888949\n",
      "210                         sellerpurchase8diffmean        0.005551        11.079454\n",
      "65                                sellerbeforesale3        0.005608        11.192748\n",
      "55                      user_unique_sellers_on_sale        0.005626        11.228019\n",
      "159          ratio_cat_int_union_user_before_seller        0.005656        11.288896\n",
      "15                                    purchase_days        0.005664        11.304294\n",
      "124       seller_unique_users_purchased_before_sale        0.005773        11.522235\n",
      "109                             selleravgactivity11        0.005804        11.584336\n",
      "66                                    selleronsale0        0.005805        11.586349\n",
      "64                                sellerbeforesale2        0.005842        11.658840\n",
      "108                             selleravgactivity10        0.005919        11.813427\n",
      "201                               selleractivity6/5        0.005929        11.832836\n",
      "113                              selleravgpurchase8        0.005953        11.881903\n",
      "123       seller_unique_items_purchased_before_sale        0.005977        11.928427\n",
      "4                                   userbeforesale2        0.006000        11.974629\n",
      "212                        sellerpurchase10diffmean        0.006015        12.005792\n",
      "127                     seller_unique_items_on_sale        0.006016        12.007956\n",
      "144          um_unique_categories_purchased_on_sale        0.006111        12.197447\n",
      "85                  seller_ratio_0_to_2_before_sale        0.006238        12.449944\n",
      "207                         sellerpurchase5diffmean        0.006279        12.531346\n",
      "141                    um_unique_categories_on_sale        0.006310        12.593552\n",
      "126                seller_unique_categories_on_sale        0.006557        13.087150\n",
      "77                              gender_avg_activity        0.006926        13.822382\n",
      "62                                sellerbeforesale0        0.006989        13.948052\n",
      "129          seller_unique_brands_purchased_on_sale        0.007722        15.411579\n",
      "118            seller_unique_categories_before_sale        0.008570        17.103929\n",
      "115                             selleravgpurchase10        0.009477        18.914961\n",
      "70                                      userseller0        0.009836        19.630418\n",
      "142                         um_unique_items_on_sale        0.010682        21.318710\n",
      "146                         um_activity_before_sale        0.010729        21.413104\n",
      "72                                      userseller2        0.031739        63.345632\n",
      "145               um_unique_items_purchased_on_sale        0.050104       100.000000\n"
     ]
    }
   ],
   "source": [
    "model_xgboost(final_feat,final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import roc_curve\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def roc_auc(X_test,y_test,y_pred,model):\n",
    "# #    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "# #    print('Confusion_Matrix: ',confusion_mat,sep='\\n')\n",
    "# #    print()\n",
    "# #    print('Accuracy of classifier on test set: {:.2f}'.format(model.score(X_test, y_test)))\n",
    "# #    print()\n",
    "   \n",
    "# #    # Classification Report\n",
    "# #    print('Classification Report: ')\n",
    "# #    print(classification_report(y_test, y_pred))\n",
    "# #    y_score = model.predict_proba(X_test)[:,1]              # Predicted probability score\n",
    "# #    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "# #    plt.figure()\n",
    "   \n",
    "#    # AuC Score & plotting of AuC curve\n",
    "#    plt.plot(fpr, tpr, label='AuC score (area = %0.2f)' % roc_auc_score(y_test, y_score))\n",
    "#    plt.plot([0, 1], [0, 1],'r--')\n",
    "#    plt.xlim([0.0, 1.0])\n",
    "#    plt.ylim([0.0, 1.05])\n",
    "#    plt.xlabel('False Positive Rate')\n",
    "#    plt.ylabel('True Positive Rate')\n",
    "#    plt.title('Receiver operating characteristic')\n",
    "#    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc(xval1,yval1,y_pred,regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Vishal/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_feat, final_label, stratify=final_label, test_size=.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth' : 10,\n",
    "    'num_leaves': 5,\n",
    "    'metric': ['l1', 'l2'],\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's l1: 0.113915\ttraining's l2: 0.0567144\tvalid_1's l1: 0.113904\tvalid_1's l2: 0.0567737\n",
      "[20]\ttraining's l1: 0.113414\ttraining's l2: 0.0564414\tvalid_1's l1: 0.113399\tvalid_1's l2: 0.0565236\n",
      "[30]\ttraining's l1: 0.113078\ttraining's l2: 0.056262\tvalid_1's l1: 0.11309\tvalid_1's l2: 0.0563785\n",
      "[40]\ttraining's l1: 0.11284\ttraining's l2: 0.0561205\tvalid_1's l1: 0.112849\tvalid_1's l2: 0.0562719\n",
      "[50]\ttraining's l1: 0.112619\ttraining's l2: 0.0559909\tvalid_1's l1: 0.112623\tvalid_1's l2: 0.0561551\n",
      "[60]\ttraining's l1: 0.112427\ttraining's l2: 0.0558787\tvalid_1's l1: 0.112424\tvalid_1's l2: 0.0560675\n",
      "[70]\ttraining's l1: 0.112265\ttraining's l2: 0.0557857\tvalid_1's l1: 0.112274\tvalid_1's l2: 0.0559988\n",
      "[80]\ttraining's l1: 0.112124\ttraining's l2: 0.0557013\tvalid_1's l1: 0.112161\tvalid_1's l2: 0.0559422\n",
      "[90]\ttraining's l1: 0.112011\ttraining's l2: 0.0556372\tvalid_1's l1: 0.112073\tvalid_1's l2: 0.0559084\n",
      "[100]\ttraining's l1: 0.111906\ttraining's l2: 0.0555748\tvalid_1's l1: 0.111998\tvalid_1's l2: 0.0558754\n"
     ]
    }
   ],
   "source": [
    "evals_result = {}  # to record eval results for plotting\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=[lgb_train, lgb_test],\n",
    "                evals_result=evals_result,\n",
    "                verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6623238745039624\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, gbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_metric(metric_name):\n",
    "    ax = lgb.plot_metric(evals_result, metric=metric_name, figsize=(10, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    # To enable interactive mode you should install ipywidgets\n",
    "    # https://github.com/jupyter-widgets/ipywidgets\n",
    "    from ipywidgets import interact, SelectMultiple\n",
    "    INTERACTIVE = True\n",
    "except ImportError:\n",
    "    INTERACTIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ace6e9865d642d3914a164e0e4d8263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='metric_name', options=('l1', 'l2'), value='l1'), Output()), _dom_c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if INTERACTIVE:\n",
    "    # create widget to switch between metrics\n",
    "    interact(render_metric, metric_name=params['metric'])\n",
    "else:\n",
    "    render_metric(params['metric'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_plot_importance(importance_type, max_features=10,\n",
    "                           ignore_zero=True, precision=3):\n",
    "    ax = lgb.plot_importance(gbm, importance_type=importance_type,\n",
    "                             max_num_features=max_features,\n",
    "                             ignore_zero=ignore_zero, figsize=(12, 8),\n",
    "                             precision=precision)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92db12dce1144e23af0ea7d2af0fe0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='importance_type', options=('split', 'gain'), value='split'), IntSl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if INTERACTIVE:\n",
    "    # create widget for interactive feature importance plot\n",
    "    interact(render_plot_importance,\n",
    "             importance_type=['split', 'gain'],\n",
    "             max_features=(1, X_train.shape[-1]),\n",
    "             precision=(0, 10))\n",
    "else:\n",
    "    render_plot_importance(importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model without seller features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>label</th>\n",
       "      <th>age_range</th>\n",
       "      <th>gender</th>\n",
       "      <th>userbeforesale0</th>\n",
       "      <th>userbeforesale1</th>\n",
       "      <th>userbeforesale2</th>\n",
       "      <th>userbeforesale3</th>\n",
       "      <th>useronsale0</th>\n",
       "      <th>useronsale1</th>\n",
       "      <th>useronsale2</th>\n",
       "      <th>useronsale3</th>\n",
       "      <th>user_ratio_0_to_2_before_sale</th>\n",
       "      <th>user_ratio_3_to_2_before_sale</th>\n",
       "      <th>user_ratio_0_to_2_on_sale</th>\n",
       "      <th>user_ratio_3_to_2_on_sale</th>\n",
       "      <th>active_days</th>\n",
       "      <th>purchase_days</th>\n",
       "      <th>useractivity5</th>\n",
       "      <th>useractivity6</th>\n",
       "      <th>useractivity7</th>\n",
       "      <th>useractivity8</th>\n",
       "      <th>useractivity9</th>\n",
       "      <th>useractivity10</th>\n",
       "      <th>useractivity11</th>\n",
       "      <th>userpurchase5</th>\n",
       "      <th>userpurchase6</th>\n",
       "      <th>userpurchase7</th>\n",
       "      <th>userpurchase8</th>\n",
       "      <th>userpurchase9</th>\n",
       "      <th>userpurchase10</th>\n",
       "      <th>userpurchase11</th>\n",
       "      <th>useravgactivity5</th>\n",
       "      <th>useravgactivity6</th>\n",
       "      <th>useravgactivity7</th>\n",
       "      <th>useravgactivity8</th>\n",
       "      <th>useravgactivity9</th>\n",
       "      <th>useravgactivity10</th>\n",
       "      <th>useravgactivity11</th>\n",
       "      <th>useravgpurchase5</th>\n",
       "      <th>useravgpurchase6</th>\n",
       "      <th>useravgpurchase7</th>\n",
       "      <th>useravgpurchase8</th>\n",
       "      <th>useravgpurchase9</th>\n",
       "      <th>useravgpurchase10</th>\n",
       "      <th>useravgpurchase11</th>\n",
       "      <th>user_unique_brands_before_sale</th>\n",
       "      <th>user_unique_categories_before_sale</th>\n",
       "      <th>user_unique_items_before_sale</th>\n",
       "      <th>user_unique_sellers_before_sale</th>\n",
       "      <th>user_unique_brands_purchased_before_sale</th>\n",
       "      <th>user_unique_categories_purchased_before_sale</th>\n",
       "      <th>user_unique_items_purchased_before_sale</th>\n",
       "      <th>user_unique_sellers_purchased_before_sale</th>\n",
       "      <th>user_unique_brands_on_sale</th>\n",
       "      <th>user_unique_categories_on_sale</th>\n",
       "      <th>user_unique_items_on_sale</th>\n",
       "      <th>user_unique_sellers_on_sale</th>\n",
       "      <th>user_unique_brands_purchased_on_sale</th>\n",
       "      <th>user_unique_categories_purchased_on_sale</th>\n",
       "      <th>user_unique_items_purchased_on_sale</th>\n",
       "      <th>user_unique_sellers_purchased_on_sale</th>\n",
       "      <th>user_all_month_purchase</th>\n",
       "      <th>user_purchase_only_11</th>\n",
       "      <th>sellerbeforesale0</th>\n",
       "      <th>sellerbeforesale1</th>\n",
       "      <th>sellerbeforesale2</th>\n",
       "      <th>sellerbeforesale3</th>\n",
       "      <th>selleronsale0</th>\n",
       "      <th>selleronsale1</th>\n",
       "      <th>selleronsale2</th>\n",
       "      <th>selleronsale3</th>\n",
       "      <th>userseller0</th>\n",
       "      <th>userseller1</th>\n",
       "      <th>userseller2</th>\n",
       "      <th>userseller3</th>\n",
       "      <th>age_avg_activity</th>\n",
       "      <th>age_avg_purchase</th>\n",
       "      <th>unique_users_age_norm</th>\n",
       "      <th>gender_avg_activity</th>\n",
       "      <th>gender_avg_purchase</th>\n",
       "      <th>unique_users_gender_norm</th>\n",
       "      <th>age_gender</th>\n",
       "      <th>age_gender_avg_activity</th>\n",
       "      <th>age_gender_avg_purchase</th>\n",
       "      <th>unique_users_age_gender_norm</th>\n",
       "      <th>age_gender_active_days_norm</th>\n",
       "      <th>age_gender_purchase_days_norm</th>\n",
       "      <th>seller_ratio_0_to_2_before_sale</th>\n",
       "      <th>seller_ratio_3_to_2_before_sale</th>\n",
       "      <th>seller_ratio_0_to_2_on_sale</th>\n",
       "      <th>seller_ratio_3_to_2_on_sale</th>\n",
       "      <th>seller_unique_brands_before_sale</th>\n",
       "      <th>seller_unique_categories_before_sale</th>\n",
       "      <th>seller_unique_items_before_sale</th>\n",
       "      <th>seller_unique_users_before_sale</th>\n",
       "      <th>seller_unique_brands_purchased_before_sale</th>\n",
       "      <th>seller_unique_categories_purchased_before_sale</th>\n",
       "      <th>seller_unique_items_purchased_before_sale</th>\n",
       "      <th>seller_unique_users_purchased_before_sale</th>\n",
       "      <th>seller_unique_brands_on_sale</th>\n",
       "      <th>seller_unique_categories_on_sale</th>\n",
       "      <th>seller_unique_items_on_sale</th>\n",
       "      <th>seller_unique_users_on_sale</th>\n",
       "      <th>seller_unique_brands_purchased_on_sale</th>\n",
       "      <th>seller_unique_categories_purchased_on_sale</th>\n",
       "      <th>seller_unique_items_purchased_on_sale</th>\n",
       "      <th>seller_unique_users_purchased_on_sale</th>\n",
       "      <th>user_merchant_pair</th>\n",
       "      <th>usersellerbeforesale0</th>\n",
       "      <th>usersellerbeforesale1</th>\n",
       "      <th>usersellerbeforesale3</th>\n",
       "      <th>userselleronsale0</th>\n",
       "      <th>userselleronsale1</th>\n",
       "      <th>userselleronsale2</th>\n",
       "      <th>userselleronsale3</th>\n",
       "      <th>um_unique_brands_on_sale</th>\n",
       "      <th>um_unique_categories_on_sale</th>\n",
       "      <th>um_unique_items_on_sale</th>\n",
       "      <th>um_unique_brands_purchased_on_sale</th>\n",
       "      <th>um_unique_categories_purchased_on_sale</th>\n",
       "      <th>um_unique_items_purchased_on_sale</th>\n",
       "      <th>um_activity_before_sale</th>\n",
       "      <th>activity_diff_from_1111</th>\n",
       "      <th>activity_diff_from_second_last</th>\n",
       "      <th>purchase_diff_from_1111</th>\n",
       "      <th>purchase_diff_from_second_last</th>\n",
       "      <th>seller_count_of_label-1</th>\n",
       "      <th>brand_intersection_user_before_on_sale</th>\n",
       "      <th>brand_intersection_user_before_and_seller</th>\n",
       "      <th>ratio_brand_int_union_user_before_on_sale</th>\n",
       "      <th>ratio_brand_int_union_user_before_seller</th>\n",
       "      <th>cat_intersection_user_before_on_sale</th>\n",
       "      <th>cat_intersection_user_before_and_seller</th>\n",
       "      <th>ratio_cat_int_union_user_before_on_sale</th>\n",
       "      <th>ratio_cat_int_union_user_before_seller</th>\n",
       "      <th>item_intersection_user_before_on_sale</th>\n",
       "      <th>item_intersection_user_before_and_seller</th>\n",
       "      <th>ratio_item_int_union_user_before_on_sale</th>\n",
       "      <th>ratio_item_int_union_user_before_seller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>130649</td>\n",
       "      <td>1</td>\n",
       "      <td>1019</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4836.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.987954</td>\n",
       "      <td>7.753050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.741350</td>\n",
       "      <td>6.668382</td>\n",
       "      <td>0.425959</td>\n",
       "      <td>3.0_1.0</td>\n",
       "      <td>102.861818</td>\n",
       "      <td>6.632899</td>\n",
       "      <td>0.445214</td>\n",
       "      <td>0.316205</td>\n",
       "      <td>0.363071</td>\n",
       "      <td>6.840170</td>\n",
       "      <td>0.632249</td>\n",
       "      <td>4.987179</td>\n",
       "      <td>0.158120</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>143</td>\n",
       "      <td>2466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>1_1019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179348</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.168478</td>\n",
       "      <td>0.054645</td>\n",
       "      <td>387.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131623</td>\n",
       "      <td>4</td>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.742450</td>\n",
       "      <td>6.229536</td>\n",
       "      <td>0.852016</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0_0.0</td>\n",
       "      <td>117.407391</td>\n",
       "      <td>6.637107</td>\n",
       "      <td>0.895509</td>\n",
       "      <td>0.725957</td>\n",
       "      <td>0.730747</td>\n",
       "      <td>21.169811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.573333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>65</td>\n",
       "      <td>4_1186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.912568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45535</td>\n",
       "      <td>6</td>\n",
       "      <td>1356</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>0.369478</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.152610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>8.363636</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>165</td>\n",
       "      <td>78</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10514.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>3293.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.542249</td>\n",
       "      <td>9.620345</td>\n",
       "      <td>0.716419</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0_0.0</td>\n",
       "      <td>154.453702</td>\n",
       "      <td>9.947552</td>\n",
       "      <td>0.697396</td>\n",
       "      <td>0.743744</td>\n",
       "      <td>0.852931</td>\n",
       "      <td>10.493014</td>\n",
       "      <td>0.708583</td>\n",
       "      <td>3.798155</td>\n",
       "      <td>0.071511</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>168</td>\n",
       "      <td>3257</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>1218</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>820</td>\n",
       "      <td>6_1356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>727.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45534</td>\n",
       "      <td>6</td>\n",
       "      <td>4249</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.052209</td>\n",
       "      <td>0.369478</td>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.152610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>8.363636</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>165</td>\n",
       "      <td>78</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9343.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.542249</td>\n",
       "      <td>9.620345</td>\n",
       "      <td>0.716419</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0_0.0</td>\n",
       "      <td>154.453702</td>\n",
       "      <td>9.947552</td>\n",
       "      <td>0.697396</td>\n",
       "      <td>0.743744</td>\n",
       "      <td>0.852931</td>\n",
       "      <td>25.388587</td>\n",
       "      <td>2.385870</td>\n",
       "      <td>5.370690</td>\n",
       "      <td>0.090517</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>3527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>217</td>\n",
       "      <td>6_4249</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132612</td>\n",
       "      <td>7</td>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>12943.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2811.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.542249</td>\n",
       "      <td>9.620345</td>\n",
       "      <td>0.716419</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0_0.0</td>\n",
       "      <td>154.453702</td>\n",
       "      <td>9.947552</td>\n",
       "      <td>0.697396</td>\n",
       "      <td>0.743744</td>\n",
       "      <td>0.852931</td>\n",
       "      <td>26.686598</td>\n",
       "      <td>1.527835</td>\n",
       "      <td>5.511765</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>296</td>\n",
       "      <td>3163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>230</td>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>134</td>\n",
       "      <td>241</td>\n",
       "      <td>7_1162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120318</td>\n",
       "      <td>424162</td>\n",
       "      <td>1679</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.027132</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>0.701550</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>150</td>\n",
       "      <td>63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40271.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>3432.0</td>\n",
       "      <td>19347.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2914.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.542249</td>\n",
       "      <td>9.620345</td>\n",
       "      <td>0.716419</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0_0.0</td>\n",
       "      <td>154.453702</td>\n",
       "      <td>9.947552</td>\n",
       "      <td>0.697396</td>\n",
       "      <td>0.743744</td>\n",
       "      <td>0.852931</td>\n",
       "      <td>35.638053</td>\n",
       "      <td>3.037168</td>\n",
       "      <td>6.639327</td>\n",
       "      <td>0.052505</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>244</td>\n",
       "      <td>5778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>127</td>\n",
       "      <td>3116</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>1893</td>\n",
       "      <td>424162_1679</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>613.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207581</td>\n",
       "      <td>424163</td>\n",
       "      <td>3826</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>104</td>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10521.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>12072.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2590.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.852055</td>\n",
       "      <td>5.584574</td>\n",
       "      <td>0.473525</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0_0.0</td>\n",
       "      <td>116.004126</td>\n",
       "      <td>5.871127</td>\n",
       "      <td>0.451581</td>\n",
       "      <td>0.361705</td>\n",
       "      <td>0.325968</td>\n",
       "      <td>12.134948</td>\n",
       "      <td>0.978085</td>\n",
       "      <td>4.661004</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>4012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>3613</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2362</td>\n",
       "      <td>424163_3826</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34156</td>\n",
       "      <td>424164</td>\n",
       "      <td>606</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.140741</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>94</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>222822.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>16727.0</td>\n",
       "      <td>37025.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.495566</td>\n",
       "      <td>7.713387</td>\n",
       "      <td>0.062622</td>\n",
       "      <td>141.133806</td>\n",
       "      <td>8.156852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0_0.0</td>\n",
       "      <td>169.742670</td>\n",
       "      <td>8.183084</td>\n",
       "      <td>0.063545</td>\n",
       "      <td>0.074476</td>\n",
       "      <td>0.063931</td>\n",
       "      <td>74.199800</td>\n",
       "      <td>5.570097</td>\n",
       "      <td>11.480620</td>\n",
       "      <td>0.201550</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2169</td>\n",
       "      <td>33125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>579</td>\n",
       "      <td>8102</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>380</td>\n",
       "      <td>2510</td>\n",
       "      <td>424164_606</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.989130</td>\n",
       "      <td>0.989071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35121</td>\n",
       "      <td>424167</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26932.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9676.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>5765.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.987954</td>\n",
       "      <td>7.753050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.741350</td>\n",
       "      <td>6.668382</td>\n",
       "      <td>0.425959</td>\n",
       "      <td>3.0_1.0</td>\n",
       "      <td>102.861818</td>\n",
       "      <td>6.632899</td>\n",
       "      <td>0.445214</td>\n",
       "      <td>0.316205</td>\n",
       "      <td>0.363071</td>\n",
       "      <td>2.783382</td>\n",
       "      <td>0.091360</td>\n",
       "      <td>2.997920</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "      <td>9425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3628.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>113</td>\n",
       "      <td>2248</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>1061</td>\n",
       "      <td>424167_1200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.890710</td>\n",
       "      <td>3628.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36151</td>\n",
       "      <td>424170</td>\n",
       "      <td>4268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.742450</td>\n",
       "      <td>6.229536</td>\n",
       "      <td>0.852016</td>\n",
       "      <td>99.741350</td>\n",
       "      <td>6.668382</td>\n",
       "      <td>0.425959</td>\n",
       "      <td>0.0_1.0</td>\n",
       "      <td>77.416906</td>\n",
       "      <td>5.293887</td>\n",
       "      <td>0.303650</td>\n",
       "      <td>0.162313</td>\n",
       "      <td>0.197636</td>\n",
       "      <td>47.595238</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>4.023529</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>1044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>162</td>\n",
       "      <td>424170_4268</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260864 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  seller_id  label  age_range  gender  userbeforesale0  userbeforesale1  userbeforesale2  userbeforesale3  useronsale0  useronsale1  useronsale2  useronsale3  user_ratio_0_to_2_before_sale  user_ratio_3_to_2_before_sale  user_ratio_0_to_2_on_sale  user_ratio_3_to_2_on_sale  active_days  purchase_days  useractivity5  useractivity6  useractivity7  useractivity8  useractivity9  useractivity10  useractivity11  userpurchase5  userpurchase6  userpurchase7  userpurchase8  userpurchase9  userpurchase10  userpurchase11  useravgactivity5  useravgactivity6  useravgactivity7  useravgactivity8  useravgactivity9  useravgactivity10  useravgactivity11  useravgpurchase5  useravgpurchase6  useravgpurchase7  useravgpurchase8  useravgpurchase9  useravgpurchase10  useravgpurchase11  user_unique_brands_before_sale  user_unique_categories_before_sale  user_unique_items_before_sale  user_unique_sellers_before_sale  user_unique_brands_purchased_before_sale  \\\n",
       "130649        1       1019      1        3.0     1.0             14.0              0.0              2.0              0.0         13.0          0.0          4.0          0.0                       7.000000                           0.00                   3.250000                        0.0            4              2       0.000000       0.000000       0.000000       0.000000       0.000000        0.484848        0.515152       0.000000       0.000000       0.000000       0.000000       0.000000        0.333333        0.666667               0.0          0.000000          0.000000          0.000000          0.000000           4.000000          17.000000               0.0               0.0          0.000000               0.0               0.0                1.0                4.0                               5                                   3                              8                                5                                       2.0   \n",
       "131623        4       1186      0        0.0     0.0             42.0              0.0              0.0              0.0          7.0          0.0          1.0          0.0                       0.000000                           0.00                   7.000000                        0.0            9              0       0.240000       0.000000       0.240000       0.000000       0.140000        0.060000        0.320000       0.000000       0.000000       0.000000       0.000000       0.000000        0.000000        1.000000              12.0          0.000000          4.000000          0.000000          3.500000           3.000000           5.333333               0.0               0.0          0.000000               0.0               0.0                0.0                1.0                              10                                  11                             26                               10                                       0.0   \n",
       "45535         6       1356      0        4.0     0.0            211.0              0.0             15.0             15.0          6.0          0.0          2.0          0.0                      14.066667                           1.00                   3.000000                        0.0           55             11       0.024096       0.084337       0.184739       0.052209       0.369478        0.132530        0.152610       0.000000       0.176471       0.235294       0.000000       0.352941        0.058824        0.176471               3.0          5.250000          5.111111          1.444444          8.363636           2.357143           5.428571               0.0               1.5          1.333333               0.0               1.5                1.0                1.5                              77                                  63                            165                               78                                      11.0   \n",
       "45534         6       4249      0        4.0     0.0            211.0              0.0             15.0             15.0          6.0          0.0          2.0          0.0                      14.066667                           1.00                   3.000000                        0.0           55             11       0.024096       0.084337       0.184739       0.052209       0.369478        0.132530        0.152610       0.000000       0.176471       0.235294       0.000000       0.352941        0.058824        0.176471               3.0          5.250000          5.111111          1.444444          8.363636           2.357143           5.428571               0.0               1.5          1.333333               0.0               1.5                1.0                1.5                              77                                  63                            165                               78                                      11.0   \n",
       "132612        7       1162      0        4.0     0.0              6.0              0.0              1.0              0.0          0.0          0.0          7.0          0.0                       6.000000                           0.00                   0.000000                        0.0            5              1       0.000000       0.285714       0.142857       0.000000       0.000000        0.000000        0.571429       0.000000       0.000000       0.000000       0.000000       0.000000        0.000000        1.000000               0.0          1.333333          2.000000          0.000000          0.000000           0.000000           4.000000               0.0               0.0          0.000000               0.0               0.0                0.0                4.0                               4                                   4                              6                                4                                       1.0   \n",
       "...         ...        ...    ...        ...     ...              ...              ...              ...              ...          ...          ...          ...          ...                            ...                            ...                        ...                        ...          ...            ...            ...            ...            ...            ...            ...             ...             ...            ...            ...            ...            ...            ...             ...             ...               ...               ...               ...               ...               ...                ...                ...               ...               ...               ...               ...               ...                ...                ...                             ...                                 ...                            ...                              ...                                       ...   \n",
       "120318   424162       1679      0        4.0     0.0            208.0              0.0              6.0              6.0         37.0          0.0          1.0          0.0                      34.666667                           1.00                  37.000000                        0.0           23              4       0.023256       0.027132       0.003876       0.031008       0.104651        0.108527        0.701550       0.285714       0.000000       0.000000       0.142857       0.428571        0.000000        0.142857               3.0          7.000000          1.000000          2.666667          5.400000           4.000000          36.200000               1.0               0.0          0.000000               1.0               3.0                0.0                1.0                              62                                  48                            150                               63                                       5.0   \n",
       "207581   424163       3826      0        2.0     0.0            130.0              0.0              4.0              2.0          2.0          0.0          2.0          0.0                      32.500000                           0.50                   1.000000                        0.0           21              2       0.035714       0.164286       0.035714       0.028571       0.000000        0.185714        0.550000       0.500000       0.166667       0.000000       0.000000       0.000000        0.000000        0.333333               2.5          3.833333          5.000000          1.000000          0.000000           8.666667          12.833333               3.0               1.0          0.000000               0.0               0.0                0.0                2.0                              33                                  25                            104                               34                                       2.0   \n",
       "34156    424164        606      0        7.0     0.0            102.0              7.0              0.0              4.0         19.0          0.0          3.0          0.0                       0.000000                           0.00                   6.333333                        0.0           22              0       0.007407       0.125926       0.066667       0.111111       0.140741        0.140741        0.407407       0.000000       0.000000       0.000000       0.000000       0.000000        0.000000        1.000000               1.0          3.400000          4.500000          5.000000          4.750000           4.750000          13.750000               0.0               0.0          0.000000               0.0               0.0                0.0                3.0                              35                                  17                             94                               36                                       0.0   \n",
       "35121    424167       1200      0        3.0     1.0             20.0              0.0              4.0              1.0          8.0          0.0          2.0          0.0                       5.000000                           0.25                   4.000000                        0.0            7              4       0.200000       0.000000       0.000000       0.000000       0.057143        0.257143        0.485714       0.166667       0.000000       0.000000       0.000000       0.000000        0.333333        0.500000               7.0          0.000000          0.000000          0.000000          2.000000           3.000000           5.666667               1.0               0.0          0.000000               0.0               0.0                1.0                1.5                               8                                   9                             11                                9                                       4.0   \n",
       "36151    424170       4268      0        0.0     1.0             26.0              0.0              0.0              0.0         13.0          0.0          1.0          0.0                       0.000000                           0.00                  13.000000                        0.0            4              0       0.000000       0.000000       0.000000       0.000000       0.000000        0.000000        1.000000       0.000000       0.000000       0.000000       0.000000       0.000000        0.000000        1.000000               0.0          0.000000          0.000000          0.000000          0.000000           0.000000           8.000000               0.0               0.0          0.000000               0.0               0.0                0.0                1.0                               4                                   3                              6                                4                                       0.0   \n",
       "\n",
       "        user_unique_categories_purchased_before_sale  user_unique_items_purchased_before_sale  user_unique_sellers_purchased_before_sale  user_unique_brands_on_sale  user_unique_categories_on_sale  user_unique_items_on_sale  user_unique_sellers_on_sale  user_unique_brands_purchased_on_sale  user_unique_categories_purchased_on_sale  user_unique_items_purchased_on_sale  user_unique_sellers_purchased_on_sale  user_all_month_purchase  user_purchase_only_11  sellerbeforesale0  sellerbeforesale1  sellerbeforesale2  sellerbeforesale3  selleronsale0  selleronsale1  selleronsale2  selleronsale3  userseller0  userseller1  userseller2  userseller3  age_avg_activity  age_avg_purchase  unique_users_age_norm  gender_avg_activity  gender_avg_purchase  unique_users_gender_norm age_gender  age_gender_avg_activity  age_gender_avg_purchase  unique_users_age_gender_norm  age_gender_active_days_norm  age_gender_purchase_days_norm  seller_ratio_0_to_2_before_sale  seller_ratio_3_to_2_before_sale  \\\n",
       "130649                                           2.0                                      2.0                                        2.0                           4                               3                          4                            4                                     1                                         1                                    1                                      1                      0.0               0.000000             4836.0                4.0              707.0              447.0         1167.0            1.0          234.0           37.0         10.0          0.0          4.0          0.0        132.987954          7.753050               1.000000            99.741350             6.668382                  0.425959    3.0_1.0               102.861818                 6.632899                      0.445214                     0.316205                       0.363071                         6.840170                         0.632249   \n",
       "131623                                           0.0                                      0.0                                        0.0                           3                               3                          3                            3                                     1                                         1                                    1                                      1                      0.0               0.023810             1122.0                5.0               53.0               53.0          343.0            1.0           75.0            2.0          4.0          0.0          1.0          0.0        105.742450          6.229536               0.852016           141.133806             8.156852                  1.000000    0.0_0.0               117.407391                 6.637107                      0.895509                     0.725957                       0.730747                        21.169811                         1.000000   \n",
       "45535                                           11.0                                     11.0                                       10.0                           4                               4                          5                            5                                     2                                         2                                    2                                      2                      0.0               0.000000            10514.0               20.0             1002.0              710.0         3293.0            4.0          867.0           62.0          2.0          0.0          1.0          1.0        147.542249          9.620345               0.716419           141.133806             8.156852                  1.000000    4.0_0.0               154.453702                 9.947552                      0.697396                     0.743744                       0.852931                        10.493014                         0.708583   \n",
       "45534                                           11.0                                     11.0                                       10.0                           4                               4                          5                            5                                     2                                         2                                    2                                      2                      0.0               0.000000             9343.0               17.0              368.0              878.0         1246.0            1.0          232.0           21.0          5.0          0.0          1.0          1.0        147.542249          9.620345               0.716419           141.133806             8.156852                  1.000000    4.0_0.0               154.453702                 9.947552                      0.697396                     0.743744                       0.852931                        25.388587                         2.385870   \n",
       "132612                                           1.0                                      1.0                                        1.0                           3                               5                          7                            3                                     3                                         5                                    7                                      3                      0.0               0.190476            12943.0                7.0              485.0              741.0         2811.0            3.0          510.0           33.0          0.0          0.0          4.0          0.0        147.542249          9.620345               0.716419           141.133806             8.156852                  1.000000    4.0_0.0               154.453702                 9.947552                      0.697396                     0.743744                       0.852931                        26.686598                         1.527835   \n",
       "...                                              ...                                      ...                                        ...                         ...                             ...                        ...                          ...                                   ...                                       ...                                  ...                                    ...                      ...                    ...                ...                ...                ...                ...            ...            ...            ...            ...          ...          ...          ...          ...               ...               ...                    ...                  ...                  ...                       ...        ...                      ...                      ...                           ...                          ...                            ...                              ...                              ...   \n",
       "120318                                           6.0                                      6.0                                        5.0                          16                              14                         30                           17                                     1                                         1                                    1                                      1                      0.0               0.000000            40271.0               90.0             1130.0             3432.0        19347.0           28.0         2914.0          153.0         20.0          0.0          1.0          0.0        147.542249          9.620345               0.716419           141.133806             8.156852                  1.000000    4.0_0.0               154.453702                 9.947552                      0.697396                     0.743744                       0.852931                        35.638053                         3.037168   \n",
       "207581                                           3.0                                      4.0                                        2.0                           3                               4                          4                            3                                     2                                         2                                    2                                      2                      0.0               0.000000            10521.0               60.0              867.0              848.0        12072.0           35.0         2590.0          226.0          3.0          0.0          1.0          0.0        101.852055          5.584574               0.473525           141.133806             8.156852                  1.000000    2.0_0.0               116.004126                 5.871127                      0.451581                     0.361705                       0.325968                        12.134948                         0.978085   \n",
       "34156                                            0.0                                      0.0                                        0.0                           6                               7                         15                            6                                     3                                         2                                    3                                      3                      0.0               0.071429           222822.0              269.0             3003.0            16727.0        37025.0           47.0         3225.0          650.0         17.0          0.0          1.0          1.0        150.495566          7.713387               0.062622           141.133806             8.156852                  1.000000    7.0_0.0               169.742670                 8.183084                      0.063545                     0.074476                       0.063931                        74.199800                         5.570097   \n",
       "35121                                            4.0                                      4.0                                        4.0                           2                               3                          5                            4                                     1                                         1                                    1                                      1                      0.0               0.000000            26932.0               34.0             9676.0              884.0         5765.0           14.0         1923.0           44.0          1.0          0.0          2.0          0.0        132.987954          7.753050               1.000000            99.741350             6.668382                  0.425959    3.0_1.0               102.861818                 6.632899                      0.445214                     0.316205                       0.363071                         2.783382                         0.091360   \n",
       "36151                                            0.0                                      0.0                                        0.0                           3                               3                         10                            3                                     1                                         1                                    1                                      1                      0.0               0.023810             1999.0               16.0               42.0              234.0          684.0            1.0          170.0           21.0         24.0          0.0          1.0          0.0        105.742450          6.229536               0.852016            99.741350             6.668382                  0.425959    0.0_1.0                77.416906                 5.293887                      0.303650                     0.162313                       0.197636                        47.595238                         5.571429   \n",
       "\n",
       "        seller_ratio_0_to_2_on_sale  seller_ratio_3_to_2_on_sale  seller_unique_brands_before_sale  seller_unique_categories_before_sale  seller_unique_items_before_sale  seller_unique_users_before_sale  seller_unique_brands_purchased_before_sale  seller_unique_categories_purchased_before_sale  seller_unique_items_purchased_before_sale  seller_unique_users_purchased_before_sale  seller_unique_brands_on_sale  seller_unique_categories_on_sale  seller_unique_items_on_sale  seller_unique_users_on_sale  seller_unique_brands_purchased_on_sale  seller_unique_categories_purchased_on_sale  seller_unique_items_purchased_on_sale  seller_unique_users_purchased_on_sale user_merchant_pair  usersellerbeforesale0  usersellerbeforesale1  usersellerbeforesale3  userselleronsale0  userselleronsale1  userselleronsale2  userselleronsale3  um_unique_brands_on_sale  um_unique_categories_on_sale  um_unique_items_on_sale  um_unique_brands_purchased_on_sale  um_unique_categories_purchased_on_sale  \\\n",
       "130649                     4.987179                     0.158120                                 2                                     8                              143                             2466                                         1.0                                             8.0                                       51.0                                      387.0                             2                                 4                           62                          534                                       1                                           4                                     24                                    134             1_1019                    0.0                    0.0                    0.0               10.0                0.0                4.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "131623                     4.573333                     0.026667                                 2                                     7                               43                              367                                         1.0                                             5.0                                       12.0                                       39.0                             2                                 7                           32                          152                                       1                                           5                                     15                                     65             4_1186                    0.0                    0.0                    0.0                4.0                0.0                1.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "45535                      3.798155                     0.071511                                 3                                    16                              168                             3257                                         2.0                                            13.0                                       98.0                                      727.0                             2                                11                           60                         1218                                       2                                           7                                     35                                    820             6_1356                    1.0                    0.0                    1.0                1.0                0.0                1.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "45534                      5.370690                     0.090517                                 2                                     2                              152                             3527                                         1.0                                             2.0                                       55.0                                      278.0                             2                                 2                           93                          513                                       1                                           1                                     37                                    217             6_4249                    4.0                    0.0                    1.0                1.0                0.0                1.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "132612                     5.511765                     0.064706                                 2                                    31                              296                             3163                                         1.0                                            22.0                                      107.0                                      246.0                             2                                22                          230                          616                                       1                                          16                                    134                                    241             7_1162                    0.0                    0.0                    0.0                0.0                0.0                4.0                0.0                         1                             2                        4                                   1                                       2   \n",
       "...                             ...                          ...                               ...                                   ...                              ...                              ...                                         ...                                             ...                                        ...                                        ...                           ...                               ...                          ...                          ...                                     ...                                         ...                                    ...                                    ...                ...                    ...                    ...                    ...                ...                ...                ...                ...                       ...                           ...                      ...                                 ...                                     ...   \n",
       "120318                     6.639327                     0.052505                                 2                                     8                              244                             5778                                         1.0                                             7.0                                      154.0                                      613.0                             2                                 7                          127                         3116                                       1                                           6                                     84                                   1893        424162_1679                   19.0                    0.0                    0.0                1.0                0.0                1.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "207581                     4.661004                     0.087259                                 3                                     7                               41                             4012                                         2.0                                             6.0                                       25.0                                      655.0                             3                                 6                           29                         3613                                       2                                           5                                     16                                   2362        424163_3826                    3.0                    0.0                    0.0                0.0                0.0                1.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "34156                     11.480620                     0.201550                                 3                                    33                             2169                            33125                                         1.0                                            26.0                                      728.0                                     1987.0                             3                                24                          579                         8102                                       1                                          22                                    380                                   2510         424164_606                    9.0                    0.0                    1.0                8.0                0.0                1.0                0.0                         1                             5                        6                                   1                                       1   \n",
       "35121                      2.997920                     0.022881                                 2                                    17                              169                             9425                                         1.0                                            10.0                                       48.0                                     3628.0                             2                                16                          113                         2248                                       1                                          12                                     73                                   1061        424167_1200                    0.0                    0.0                    0.0                1.0                0.0                2.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "36151                      4.023529                     0.123529                                 5                                     4                               95                             1044                                         1.0                                             3.0                                       12.0                                       38.0                             2                                 3                           33                          329                                       1                                           3                                     15                                    162        424170_4268                   23.0                    0.0                    0.0                1.0                0.0                1.0                0.0                         1                             1                        1                                   1                                       1   \n",
       "\n",
       "        um_unique_items_purchased_on_sale  um_activity_before_sale  activity_diff_from_1111  activity_diff_from_second_last  purchase_diff_from_1111  purchase_diff_from_second_last  seller_count_of_label-1  brand_intersection_user_before_on_sale  brand_intersection_user_before_and_seller  ratio_brand_int_union_user_before_on_sale  ratio_brand_int_union_user_before_seller  cat_intersection_user_before_on_sale  cat_intersection_user_before_and_seller  ratio_cat_int_union_user_before_on_sale  ratio_cat_int_union_user_before_seller  item_intersection_user_before_on_sale  item_intersection_user_before_and_seller  ratio_item_int_union_user_before_on_sale  ratio_item_int_union_user_before_seller  \n",
       "130649                                  1                      0.0                 0.179348                        0.065574                 0.168478                        0.054645                    387.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "131623                                  1                      0.0                 0.913043                        0.912568                 0.000000                        0.000000                     39.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "45535                                   1                      2.0                 0.989130                        0.983607                 0.847826                        0.836066                    727.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      1.0                                      0.0                                0.043478                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "45534                                   1                      5.0                 0.989130                        0.983607                 0.847826                        0.836066                    278.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "132612                                  4                      0.0                 0.842391                        0.841530                 0.005435                        0.000000                    246.0                                     1.0                                        0.0                                   0.333333                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "...                                   ...                      ...                      ...                             ...                      ...                             ...                      ...                                     ...                                        ...                                        ...                                       ...                                   ...                                      ...                                      ...                                     ...                                    ...                                       ...                                       ...                                      ...  \n",
       "120318                                  1                     19.0                 0.978261                        0.978142                 0.978261                        0.732240                    613.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "207581                                  1                      3.0                 0.978261                        0.978142                 0.978261                        0.191257                    655.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "34156                                   1                     10.0                 0.989130                        0.989071                 0.000000                        0.000000                   1987.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "35121                                   1                      0.0                 0.902174                        0.890710                 0.902174                        0.890710                   3628.0                                     1.0                                        1.0                                   0.250000                                      0.25                                   0.0                                      1.0                                      0.0                                0.125000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "36151                                   1                     23.0                 0.032609                        0.016393                 0.000000                        0.000000                     38.0                                     0.0                                        0.0                                   0.000000                                      0.00                                   0.0                                      0.0                                      0.0                                0.000000                                    0.0                                       0.0                                       0.0                                      0.0  \n",
       "\n",
       "[260864 rows x 141 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without Seller monthly features\n",
    "\n",
    "df_combined.iloc[:,pd.np.r_[0:93, 121:169]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort\n",
    "df_combined = df_combined.sort_values(['user_id','seller_id'])\n",
    "df_train = df_train.sort_values(['user_id','seller_id'])\n",
    "\n",
    "final_feat = (df_combined.iloc[:,pd.np.r_[0:93, 121:169]]\\\n",
    "              .drop(['user_id', 'seller_id', 'label','age_gender', 'user_merchant_pair'], axis=1))\n",
    "\n",
    "final_label = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Iteration Complete!!\n",
      "Mean auc for validation =  0.6747761287680629 \t Mean auc for valid baseline = 0.6498\n",
      "Mean auc for train =  0.7782986218836969 \t Mean auc for train baseline = 0.6629\n",
      "                                            feature  importance_abs  importance_norm\n",
      "135         ratio_item_int_union_user_before_seller        0.000000         0.000000\n",
      "79                         unique_users_gender_norm        0.000000         0.000000\n",
      "106                           usersellerbeforesale1        0.000000         0.000000\n",
      "109                               userselleronsale1        0.000000         0.000000\n",
      "110                               userselleronsale2        0.000000         0.000000\n",
      "123                         seller_count_of_label-1        0.000000         0.000000\n",
      "125       brand_intersection_user_before_and_seller        0.000000         0.000000\n",
      "128            cat_intersection_user_before_on_sale        0.000000         0.000000\n",
      "129         cat_intersection_user_before_and_seller        0.000000         0.000000\n",
      "78                              gender_avg_purchase        0.000000         0.000000\n",
      "133        item_intersection_user_before_and_seller        0.000000         0.000000\n",
      "124          brand_intersection_user_before_on_sale        0.003119         5.344738\n",
      "84                    age_gender_purchase_days_norm        0.003989         6.836121\n",
      "1                                            gender        0.004261         7.301211\n",
      "3                                   userbeforesale1        0.004729         8.104476\n",
      "127        ratio_brand_int_union_user_before_seller        0.004799         8.223691\n",
      "39                                 useravgpurchase7        0.004802         8.229576\n",
      "27                                    userpurchase9        0.004968         8.512503\n",
      "7                                       useronsale1        0.005301         9.084333\n",
      "82                     unique_users_age_gender_norm        0.005349         9.166218\n",
      "31                                 useravgactivity6        0.005411         9.272028\n",
      "9                                       useronsale3        0.005436         9.314961\n",
      "43                                useravgpurchase11        0.005473         9.379537\n",
      "56             user_unique_brands_purchased_on_sale        0.005490         9.408471\n",
      "54                        user_unique_items_on_sale        0.005513         9.448038\n",
      "49     user_unique_categories_purchased_before_sale        0.005568         9.541764\n",
      "24                                    userpurchase6        0.005606         9.606989\n",
      "74                                 age_avg_activity        0.005607         9.609163\n",
      "30                                 useravgactivity5        0.005609         9.612523\n",
      "53                   user_unique_categories_on_sale        0.005613         9.618646\n",
      "112                        um_unique_brands_on_sale        0.005653         9.686521\n",
      "61                            user_purchase_only_11        0.005664         9.706227\n",
      "76                            unique_users_age_norm        0.005691         9.751569\n",
      "19                                    useractivity8        0.005722         9.805180\n",
      "132           item_intersection_user_before_on_sale        0.005726         9.812240\n",
      "32                                 useravgactivity7        0.005738         9.832778\n",
      "41                                 useravgpurchase9        0.005739         9.833698\n",
      "42                                useravgpurchase10        0.005743         9.841410\n",
      "8                                       useronsale2        0.005781         9.906492\n",
      "59            user_unique_sellers_purchased_on_sale        0.005822         9.977111\n",
      "2                                   userbeforesale0        0.005837        10.002477\n",
      "45               user_unique_categories_before_sale        0.005841        10.009053\n",
      "23                                    userpurchase5        0.005844        10.015090\n",
      "34                                 useravgactivity9        0.005860        10.041635\n",
      "17                                    useractivity6        0.005907        10.121654\n",
      "26                                    userpurchase8        0.005910        10.126849\n",
      "35                                useravgactivity10        0.005915        10.135717\n",
      "40                                 useravgpurchase8        0.005934        10.169566\n",
      "5                                   userbeforesale3        0.005970        10.230273\n",
      "121                         purchase_diff_from_1111        0.005985        10.255589\n",
      "120                  activity_diff_from_second_last        0.006022        10.319006\n",
      "33                                 useravgactivity8        0.006038        10.347569\n",
      "28                                   userpurchase10        0.006043        10.355598\n",
      "25                                    userpurchase7        0.006045        10.359264\n",
      "108                               userselleronsale0        0.006050        10.367745\n",
      "29                                   userpurchase11        0.006053        10.373386\n",
      "18                                    useractivity7        0.006054        10.374896\n",
      "58              user_unique_items_purchased_on_sale        0.006086        10.429892\n",
      "20                                    useractivity9        0.006100        10.452338\n",
      "6                                       useronsale0        0.006152        10.541526\n",
      "10                    user_ratio_0_to_2_before_sale        0.006213        10.646770\n",
      "134        ratio_item_int_union_user_before_on_sale        0.006226        10.668455\n",
      "44                   user_unique_brands_before_sale        0.006245        10.701118\n",
      "119                         activity_diff_from_1111        0.006270        10.745102\n",
      "36                                useravgactivity11        0.006310        10.812893\n",
      "71                                      userseller1        0.006352        10.885527\n",
      "13                        user_ratio_3_to_2_on_sale        0.006357        10.894305\n",
      "93       seller_unique_brands_purchased_before_sale        0.006385        10.942026\n",
      "46                    user_unique_items_before_sale        0.006400        10.966492\n",
      "16                                    useractivity5        0.006426        11.011400\n",
      "57         user_unique_categories_purchased_on_sale        0.006432        11.021909\n",
      "12                        user_ratio_0_to_2_on_sale        0.006438        11.032707\n",
      "83                      age_gender_active_days_norm        0.006454        11.059489\n",
      "38                                 useravgpurchase6        0.006512        11.158627\n",
      "48         user_unique_brands_purchased_before_sale        0.006560        11.240813\n",
      "105                           usersellerbeforesale0        0.006642        11.382046\n",
      "21                                   useractivity10        0.006786        11.627940\n",
      "11                    user_ratio_3_to_2_before_sale        0.006789        11.633672\n",
      "0                                         age_range        0.006923        11.863869\n",
      "73                                      userseller3        0.007068        12.112111\n",
      "126       ratio_brand_int_union_user_before_on_sale        0.007072        12.119101\n",
      "47                  user_unique_sellers_before_sale        0.007133        12.224126\n",
      "89                 seller_unique_brands_before_sale        0.007136        12.228328\n",
      "107                           usersellerbeforesale3        0.007173        12.291281\n",
      "14                                      active_days        0.007270        12.457970\n",
      "65                                sellerbeforesale3        0.007297        12.503993\n",
      "87                      seller_ratio_0_to_2_on_sale        0.007318        12.539608\n",
      "130         ratio_cat_int_union_user_before_on_sale        0.007470        12.800614\n",
      "60                          user_all_month_purchase        0.007552        12.941627\n",
      "37                                 useravgpurchase5        0.007594        13.012934\n",
      "51        user_unique_sellers_purchased_before_sale        0.007629        13.073179\n",
      "111                               userselleronsale3        0.007636        13.085174\n",
      "75                                 age_avg_purchase        0.007709        13.211171\n",
      "50          user_unique_items_purchased_before_sale        0.007714        13.219586\n",
      "102      seller_unique_categories_purchased_on_sale        0.007785        13.340142\n",
      "80                          age_gender_avg_activity        0.007827        13.413210\n",
      "115              um_unique_brands_purchased_on_sale        0.007864        13.475209\n",
      "81                          age_gender_avg_purchase        0.007880        13.502792\n",
      "101          seller_unique_brands_purchased_on_sale        0.008029        13.758938\n",
      "94   seller_unique_categories_purchased_before_sale        0.008035        13.768943\n",
      "122                  purchase_diff_from_second_last        0.008121        13.915665\n",
      "100                     seller_unique_users_on_sale        0.008126        13.925146\n",
      "88                      seller_ratio_3_to_2_on_sale        0.008185        14.025262\n",
      "55                      user_unique_sellers_on_sale        0.008341        14.293491\n",
      "131          ratio_cat_int_union_user_before_seller        0.008463        14.501762\n",
      "67                                    selleronsale1        0.008491        14.550330\n",
      "97                     seller_unique_brands_on_sale        0.008534        14.623882\n",
      "92                  seller_unique_users_before_sale        0.008549        14.649713\n",
      "52                       user_unique_brands_on_sale        0.008671        14.859436\n",
      "77                              gender_avg_activity        0.008675        14.866578\n",
      "103           seller_unique_items_purchased_on_sale        0.008729        14.958910\n",
      "86                  seller_ratio_3_to_2_before_sale        0.008858        15.180020\n",
      "104           seller_unique_users_purchased_on_sale        0.008886        15.228017\n",
      "91                  seller_unique_items_before_sale        0.009040        15.490818\n",
      "66                                    selleronsale0        0.009184        15.738752\n",
      "113                    um_unique_categories_on_sale        0.009223        15.805518\n",
      "98                 seller_unique_categories_on_sale        0.009230        15.817689\n",
      "22                                   useractivity11        0.009248        15.847780\n",
      "63                                sellerbeforesale1        0.009598        16.446725\n",
      "95        seller_unique_items_purchased_before_sale        0.009644        16.526738\n",
      "62                                sellerbeforesale0        0.009660        16.553293\n",
      "85                  seller_ratio_0_to_2_before_sale        0.009708        16.635993\n",
      "116          um_unique_categories_purchased_on_sale        0.010028        17.183933\n",
      "69                                    selleronsale3        0.010227        17.525914\n",
      "68                                    selleronsale2        0.010400        17.821458\n",
      "90             seller_unique_categories_before_sale        0.010555        18.087327\n",
      "99                      seller_unique_items_on_sale        0.010740        18.404896\n",
      "64                                sellerbeforesale2        0.010852        18.595541\n",
      "96        seller_unique_users_purchased_before_sale        0.011012        18.870799\n",
      "4                                   userbeforesale2        0.011022        18.887582\n",
      "15                                    purchase_days        0.011036        18.911341\n",
      "70                                      userseller0        0.014283        24.475939\n",
      "118                         um_activity_before_sale        0.015933        27.302825\n",
      "114                         um_unique_items_on_sale        0.016224        27.802443\n",
      "72                                      userseller2        0.049690        85.151054\n",
      "117               um_unique_items_purchased_on_sale        0.058355       100.000000\n"
     ]
    }
   ],
   "source": [
    "model_xgboost(final_feat,final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def roc_auc(X_test,y_test,y_pred,model):\n",
    "#    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "#    print('Confusion_Matrix: ',confusion_mat,sep='\\n')\n",
    "#    print()\n",
    "#    print('Accuracy of classifier on test set: {:.2f}'.format(model.score(X_test, y_test)))\n",
    "#    print()\n",
    "   \n",
    "#    # Classification Report\n",
    "#    print('Classification Report: ')\n",
    "#    print(classification_report(y_test, y_pred))\n",
    "#    y_score = model.predict_proba(X_test)[:,1]              # Predicted probability score\n",
    "#    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "#    plt.figure()\n",
    "   \n",
    "   # AuC Score & plotting of AuC curve\n",
    "   plt.plot(fpr, tpr, label='AuC score (area = %0.2f)' % roc_auc_score(y_test, y_score))\n",
    "   plt.plot([0, 1], [0, 1],'r--')\n",
    "   plt.xlim([0.0, 1.0])\n",
    "   plt.ylim([0.0, 1.05])\n",
    "   plt.xlabel('False Positive Rate')\n",
    "   plt.ylabel('True Positive Rate')\n",
    "   plt.title('Receiver operating characteristic')\n",
    "   plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR PREDICTION VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ee4decdca3b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_xgboost_pred(x, y):\n",
    "    \n",
    "    model = xgb.XGBClassifier()\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 2)\n",
    "    \n",
    "    AUC_valid = []\n",
    "    AUC_train = []\n",
    "    \n",
    "    for train_index, valid_index in skf.split(x, y):\n",
    "    \n",
    "        #print(\"TRAIN:\", train_index, \"VALID:\", valid_index)\n",
    "    \n",
    "        X_train1, X_valid1 = x.iloc[train_index], x.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "        X_train = X_train1.drop(['user_id', 'seller_id', 'label','age_gender', 'user_merchant_pair'], axis=1)\n",
    "        X_valid = X_valid1.drop(['user_id', 'seller_id', 'label','age_gender', 'user_merchant_pair'], axis=1)\n",
    "    \n",
    "        model.fit(X_train, y_train, eval_metric='auc')\n",
    "        \n",
    "        auc_valid = roc_auc_score(y_valid, model.predict_proba(X_valid)[:,1])\n",
    "        #print(auc_valid)\n",
    "        AUC_valid.append(auc_valid)\n",
    "        Å\n",
    "        X_train1['prediction'] = model.predict_proba(X_train)[:,1]\n",
    "        X_valid1['prediction'] = model.predict_proba(X_valid)[:,1]\n",
    "        \n",
    "        auc_train = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n",
    "        #print(auc_train)\n",
    "        AUC_train.append(auc_train)\n",
    "        \n",
    "        break\n",
    "        \n",
    "    def mean(z):\n",
    "        return sum(z)/len(z)\n",
    "    \n",
    "    print(\"Mean auc for validation = \", mean(AUC_valid), \"\\t Mean auc for valid baseline = 0.6498\")\n",
    "    print(\"Mean auc for train = \", mean(AUC_train), \"\\t Mean auc for train baseline = 0.6629\")\n",
    "        \n",
    "    feat_imp_abs = model.feature_importances_\n",
    "    feat_imp_abs = pd.Series(data=feat_imp_abs,dtype='float')\n",
    "    feat_imp_norm = feat_imp_abs.div(feat_imp_abs.max())*100    \n",
    "        \n",
    "    feature_importance = list(final_feat)\n",
    "    feature_importance = pd.DataFrame(feature_importance)\n",
    "    feature_importance['importance_abs'] = feat_imp_abs\n",
    "    feature_importance['importance_norm'] = feat_imp_norm\n",
    "    feature_importance = feature_importance.rename(columns={0: \"feature\"})\n",
    "    \n",
    "    print(feature_importance.sort_values('importance_norm'))\n",
    "    \n",
    "    return X_train1, X_valid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort\n",
    "df_combined = df_combined.sort_values(['user_id','seller_id'])\n",
    "df_train = df_train.sort_values(['user_id','seller_id'])\n",
    "\n",
    "final_feat = (df_combined.drop(['user_id', 'seller_id', 'label','age_gender', 'user_merchant_pair'], axis=1))\n",
    "\n",
    "final_label = df_train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To add prediction to features df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1,X_valid1 = model_xgboost(df_combined, final_label)\n",
    "\n",
    "# prediction = pd.concat([X_train1,X_valid1],ignore_index = True)\n",
    "\n",
    "# cols = prediction.columns.tolist()\n",
    "\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "# prediction = prediction[cols]\n",
    "\n",
    "# prediction = prediction.sort_values('prediction', ascending = False)\n",
    "\n",
    "# prediction.to_csv(\"prediction1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs = GridSearchCV(xgb_model, {\"model__max_depth\": [5, 10],\n",
    "#                               \"model__min_child_weight\": [5, 10],\n",
    "#                               \"model__n_estimators\": [25]},\n",
    "#                   n_jobs=-1, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gs.best_params_)\n",
    "# print(gs.best_score_)\n",
    "# xgb_model.set_params(**gs.best_params_)\n",
    "# xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_weights(xgb_model, top = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eli5 = xgb.XGBClassifier(max_depth = 6)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, valid_index in skf.split(final_feat, final_label):\n",
    "    \n",
    "    X_train, X_valid = final_feat.iloc[train_index], final_feat.iloc[valid_index]\n",
    "    y_train, y_valid = final_label.iloc[train_index], final_label.iloc[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eli5.fit(X_train, y_train, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(final_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0cb0062529c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m eli5.show_prediction(xgb_model, \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      feature_names=features, show_feature_values=True, top = 50)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[4]],\n",
    "                     feature_names=features, show_feature_values=True, top = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import roc_curve\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def roc_auc(x,y,y_pred,model):\n",
    "#    confusion_mat = confusion_matrix(y, y_pred)\n",
    "#    print('Confusion_Matrix: ',confusion_mat,sep='\\n')\n",
    "#    print()\n",
    "#    print('Accuracy of classifier on test set: {:.2f}'.format(model.score(x, y)))\n",
    "#    print()\n",
    "   \n",
    "#    # Classification Report\n",
    "#    print('Classification Report: ')\n",
    "#    print(classification_report(y, y_pred))\n",
    "#    y_score = model.predict_proba(X_test)[:,1]              # Predicted probability score\n",
    "#    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "#    plt.figure()\n",
    "   \n",
    "#    # AuC Score & plotting of AuC curve\n",
    "#    plt.plot(fpr, tpr, label='AuC score (area = %0.2f)' % roc_auc_score(y, y_score))\n",
    "#    plt.plot([0, 1], [0, 1],'r--')\n",
    "#    plt.xlim([0.0, 1.0])\n",
    "#    plt.ylim([0.0, 1.05])\n",
    "#    plt.xlabel('False Positive Rate')\n",
    "#    plt.ylabel('True Positive Rate')\n",
    "#    plt.title('Receiver operating characteristic')\n",
    "#    plt.legend(loc=\"lower right\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(xval1,yval1,y_pred,regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(final_feat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-37798c72d835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m eli5.show_prediction(xgb_model, \n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      feature_names=features, show_feature_values=True, top = 20)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[4]],\n",
    "                     feature_names=features, show_feature_values=True, top = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[10]],\n",
    "                     feature_names=features, show_feature_values=True, top = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[78]],\n",
    "                     feature_names=features, show_feature_values=True, top = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[21]],\n",
    "                     feature_names=features, show_feature_values=True, top = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[1570]],\n",
    "                     feature_names=features, show_feature_values=True, top = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[5570]],\n",
    "                     feature_names=features, show_feature_values=True, top = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(xgb_model, \n",
    "                     X_test.iloc[[5570]],\n",
    "                     feature_names=features, show_feature_values=True, top = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predict_proba = xgb_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(final_feat, xgb_predict_proba, num_features=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# Need to load JS vis in the notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[5,:], X_train.iloc[5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[1000,:], X_train.iloc[1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[50,:], X_train.iloc[50,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits = 5, random_state = 0)\n",
    "\n",
    "# for train_index, valid_index in skf.split(final_feat, final_label):\n",
    "#     print(\"TRAIN:\", train_index, \"VALID:\", valid_index)\n",
    "#     X_train, X_valid = final_feat.iloc[train_index], final_feat.iloc[valid_index]\n",
    "#     y_train, y_valid = final_label.iloc[train_index], final_label.iloc[valid_index]\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     print( roc_auc_score(y_valid, model.predict_proba(X_valid)[:,1]) )\n",
    "    \n",
    "#     #accuracy = model.score(X_valid, y_valid)\n",
    "    \n",
    "#     #y_pred = model.predict(X_valid)\n",
    "    \n",
    "#     #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_valid, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
